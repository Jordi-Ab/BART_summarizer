{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad32f15f-59ca-41f5-8ef1-1d3fc0754bd7",
   "metadata": {},
   "source": [
    "In this script we prepare the Data for the BART fine tuning task by making sure that the tokenized text and summaries dont exceed 1024 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ed96da-6327-449c-9fb1-b6651b780c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1371d2-330a-4a8a-8b29-eb4aa3c41ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large\"  # or another BART variant\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4637ba56-faad-4ed9-badd-c4fc20b0415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\").to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b776592-2509-44a3-a274-11e76f4ede4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress_bar(iteration, total, bar_length=50):\n",
    "    progress = float(iteration) / float(total)\n",
    "    arrow = '=' * int(round(progress * bar_length) - 1)\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    print(f'Progress: [{arrow + spaces}] {int(progress * 100)}%', end='\\r')\n",
    "    \n",
    "def finish_summary(summary_str):\n",
    "    summ_splitted = summary_str.split('.')\n",
    "    finished_summ = '.'.join(summ_splitted[:-1])\n",
    "    finished_summ += '.'\n",
    "    return finished_summ\n",
    "\n",
    "def get_most_relevant_sentences(article_text, embeddings_model, top_n_perc = .2):\n",
    "    \"\"\"\n",
    "    Extract only the \"top_n_perc\" sentences of a text \"article_text\".\n",
    "    Top n sentences are considered the sentences that are most similar to the whole text.\n",
    "    It is kind of a simple extractive summarization.\n",
    "    Steps:\n",
    "     1. The embedding of the whole text is computed. \n",
    "     2. The whole text is broken into individual sentences.\n",
    "     3 Embeddings of each individual sentence are computed.\n",
    "     4. Cosine similarity of each individual sentences against the embedding of the whole text is computed.\n",
    "     5. Get top n sentences (sentences that more closely resembele the idea of the whole text).\n",
    "    Receives:\n",
    "     - article_text: str: The text of a news article.\n",
    "     - embeddings_model: object: The model that will be used for embeddings. Model should have a .encode functionality to compute the embeddings.\n",
    "    Returns:\n",
    "     - Text containing only the top n % most representative sentences of a text.\n",
    "    \"\"\"\n",
    "    # compute embedding of the whole text\n",
    "    whole_text_embedding = embeddings_model.encode(article_text, show_progress_bar=False)\n",
    "    # break text in sentences\n",
    "    sentences = nltk.sent_tokenize(article_text)\n",
    "    # store the sentences in a DataFrame\n",
    "    sentences_df = pd.DataFrame(sentences, columns=['sentence'])\n",
    "    # compute embeddings of each sentence individually\n",
    "    sentences_embeddings = embeddings_model.encode(sentences, show_progress_bar=False)\n",
    "     \n",
    "    # compute cosine similarities of the whole text vs each individual sentence\n",
    "    cosine_sims = cosine_similarity(\n",
    "        whole_text_embedding.reshape(1, -1), \n",
    "        sentences_embeddings\n",
    "    )\n",
    "    # store cosine similarities on a column of the DataFrame\n",
    "    sentences_df['similarity'] = cosine_sims[0]\n",
    "    sentences_df.reset_index(inplace=True)\n",
    "    # n sentences tied to top_n_perc of the article\n",
    "    top_n = round(len(sentences)*top_n_perc)\n",
    "    # Top n percent sentences that capture the main idea, sorted by how they appear in the text\n",
    "    most_relevant_sentences = sentences_df.sort_values(\n",
    "        # sort by similarity\n",
    "        by='similarity', \n",
    "        # most similars at the top\n",
    "        ascending=False\n",
    "    ).head(\n",
    "        # top 20%\n",
    "        top_n\n",
    "    ).sort_values(\n",
    "        # sort them back by how they appear in the original text\n",
    "        by='index'\n",
    "    )[\n",
    "        # get senteces\n",
    "        'sentence'\n",
    "    ].values.tolist() # to python list\n",
    "    return ' '.join(most_relevant_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463a18d-c911-4bc7-86b6-b1ce48968778",
   "metadata": {},
   "source": [
    "# Load Data Set\n",
    "DataSet consists of 295,174 news articles scrapped from a Mexican Newspaper, along with its summary. Summaries were created using `StableBeluga-7B` as the teacher. I left the LLM running for several days (weeks) in order to get all the summaries.\n",
    "\n",
    "Relevant Columns:\n",
    "- `h1`: Is the title of the news articles. Is used as key to merge with the news articles information.\n",
    "- `date`: Date and time when the news articles was published.\n",
    "- `author`: Name of the author who published the article.\n",
    "- `content`: Article text in spanish.\n",
    "- `h1_en`: Article title translated to english.\n",
    "- `content_en`: Article text translated to English.\n",
    "- `summary`: Summary generated by `StableBeluga-7B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f0ee96-f9ec-4589-afbc-0c5335c61550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the StableBeluga summaries data set\n",
    "with open('datasets/summarized_news.json', \"r\") as f:\n",
    "    summaries = json.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f1db09-aca7-458f-af68-da4c8d22ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "summs_df = pd.DataFrame.from_dict(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2face835-64ea-499d-8c8a-698007e5d64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295174, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98de13e3-0c91-4ed5-a300-74f8a7bd2f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>h1_en</th>\n",
       "      <th>h2_en</th>\n",
       "      <th>content_en</th>\n",
       "      <th>content_len</th>\n",
       "      <th>summary</th>\n",
       "      <th>article_summary_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cancelan “Noche de Rábanos” en Oaxaca por ries...</td>\n",
       "      <td>A través de un video, el gobernador Alejandro ...</td>\n",
       "      <td>Más Información</td>\n",
       "      <td>23/12/2021 09:09</td>\n",
       "      <td>Fernando Miranda / Corresponsal</td>\n",
       "      <td>.– Ante el  aumento de casos de Covid-19 y en ...</td>\n",
       "      <td>“Night of Radishes” Canceled in Oaxaca by Risk...</td>\n",
       "      <td>Through a video, Governor Alejandro Murat repo...</td>\n",
       "      <td>.– In view of the increase in Covid-19 cases a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The government of Oaxaca cancelled the traditi...</td>\n",
       "      <td>0.834634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pepenadores se casan en relleno sanitario, don...</td>\n",
       "      <td>Con apoyo de las autoridades de Ciudad Victori...</td>\n",
       "      <td>Más Información</td>\n",
       "      <td>17/12/2019 00:02</td>\n",
       "      <td>Redacción El Universal</td>\n",
       "      <td>Jesús Gallegos y Juana Martínez se conocieron ...</td>\n",
       "      <td>Pepenadores get married in sanitary filling, w...</td>\n",
       "      <td>With the support of the authorities of Ciudad ...</td>\n",
       "      <td>Jesús Gallegos and Juana Martínez met five yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jesús Gallegos and Juana Martínez met five yea...</td>\n",
       "      <td>0.769818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ladrón se mete a casa en Coyoacán de diputada ...</td>\n",
       "      <td>La legisladora Edna Laura Huerta Ruiz dijo a l...</td>\n",
       "      <td>Más Información</td>\n",
       "      <td>29/03/2021 14:41</td>\n",
       "      <td>Redacción</td>\n",
       "      <td>La diputada federal por Morena, Edna Laura Hue...</td>\n",
       "      <td>Thief enters home in Coyoacán as federal deput...</td>\n",
       "      <td>Legislator Edna Laura Huerta Ruiz told the aut...</td>\n",
       "      <td>The federal deputy for Morena, Edna Laura Huer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Federal deputy Edna Laura Huerta Ruiz was a vi...</td>\n",
       "      <td>0.718933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automovilistas evitan atraco y tunden a golpes...</td>\n",
       "      <td>Los conductores que atestiguaron un robo sobre...</td>\n",
       "      <td>Más Información</td>\n",
       "      <td>15/09/2021 09:31</td>\n",
       "      <td>Redacción El Universal</td>\n",
       "      <td>Tras asaltar a punta de pistola  a tres automo...</td>\n",
       "      <td>Motorists avoid robbery and beat up thief in I...</td>\n",
       "      <td>The drivers who testified to a robbery over th...</td>\n",
       "      <td>After assaulting three motorists at gunpoint, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A repeat thief who assaulted three motorists a...</td>\n",
       "      <td>0.819494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mancera ve condiciones para que Senado apruebe...</td>\n",
       "      <td>El coordinador del PRD reconoció que la resolu...</td>\n",
       "      <td>Más Información</td>\n",
       "      <td>12/05/2022 16:41</td>\n",
       "      <td>Redacción</td>\n",
       "      <td>El senador Miguel Ángel Mancera  aseguró que h...</td>\n",
       "      <td>Mancera sees conditions for Senate to approve ...</td>\n",
       "      <td>The PRD coordinator acknowledged that the Cour...</td>\n",
       "      <td>Senator Miguel Ángel Mancera said that there a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senator Miguel Ángel Mancera has said that the...</td>\n",
       "      <td>0.857370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  h1  \\\n",
       "0  Cancelan “Noche de Rábanos” en Oaxaca por ries...   \n",
       "1  Pepenadores se casan en relleno sanitario, don...   \n",
       "2  Ladrón se mete a casa en Coyoacán de diputada ...   \n",
       "3  Automovilistas evitan atraco y tunden a golpes...   \n",
       "4  Mancera ve condiciones para que Senado apruebe...   \n",
       "\n",
       "                                                  h2               h3  \\\n",
       "0  A través de un video, el gobernador Alejandro ...  Más Información   \n",
       "1  Con apoyo de las autoridades de Ciudad Victori...  Más Información   \n",
       "2  La legisladora Edna Laura Huerta Ruiz dijo a l...  Más Información   \n",
       "3  Los conductores que atestiguaron un robo sobre...  Más Información   \n",
       "4  El coordinador del PRD reconoció que la resolu...  Más Información   \n",
       "\n",
       "               date                            author  \\\n",
       "0  23/12/2021 09:09  Fernando Miranda / Corresponsal    \n",
       "1  17/12/2019 00:02            Redacción El Universal   \n",
       "2  29/03/2021 14:41                        Redacción    \n",
       "3  15/09/2021 09:31            Redacción El Universal   \n",
       "4  12/05/2022 16:41                        Redacción    \n",
       "\n",
       "                                             content  \\\n",
       "0  .– Ante el  aumento de casos de Covid-19 y en ...   \n",
       "1  Jesús Gallegos y Juana Martínez se conocieron ...   \n",
       "2  La diputada federal por Morena, Edna Laura Hue...   \n",
       "3  Tras asaltar a punta de pistola  a tres automo...   \n",
       "4  El senador Miguel Ángel Mancera  aseguró que h...   \n",
       "\n",
       "                                               h1_en  \\\n",
       "0  “Night of Radishes” Canceled in Oaxaca by Risk...   \n",
       "1  Pepenadores get married in sanitary filling, w...   \n",
       "2  Thief enters home in Coyoacán as federal deput...   \n",
       "3  Motorists avoid robbery and beat up thief in I...   \n",
       "4  Mancera sees conditions for Senate to approve ...   \n",
       "\n",
       "                                               h2_en  \\\n",
       "0  Through a video, Governor Alejandro Murat repo...   \n",
       "1  With the support of the authorities of Ciudad ...   \n",
       "2  Legislator Edna Laura Huerta Ruiz told the aut...   \n",
       "3  The drivers who testified to a robbery over th...   \n",
       "4  The PRD coordinator acknowledged that the Cour...   \n",
       "\n",
       "                                          content_en  content_len  \\\n",
       "0  .– In view of the increase in Covid-19 cases a...          NaN   \n",
       "1  Jesús Gallegos and Juana Martínez met five yea...          NaN   \n",
       "2  The federal deputy for Morena, Edna Laura Huer...          NaN   \n",
       "3  After assaulting three motorists at gunpoint, ...          NaN   \n",
       "4  Senator Miguel Ángel Mancera said that there a...          NaN   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The government of Oaxaca cancelled the traditi...   \n",
       "1  Jesús Gallegos and Juana Martínez met five yea...   \n",
       "2  Federal deputy Edna Laura Huerta Ruiz was a vi...   \n",
       "3  A repeat thief who assaulted three motorists a...   \n",
       "4  Senator Miguel Ángel Mancera has said that the...   \n",
       "\n",
       "   article_summary_similarity  \n",
       "0                    0.834634  \n",
       "1                    0.769818  \n",
       "2                    0.718933  \n",
       "3                    0.819494  \n",
       "4                    0.857370  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summs_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abe05e65-443b-4e2f-8cbe-13ebe43623bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ix = np.random.randint(200000)\n",
    "cont = summs_df.iloc[rand_ix]['content_en']\n",
    "summ = summs_df.iloc[rand_ix]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "835f393a-7283-4c27-a9f5-b55e3eb73368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \n",
      "Today is July 21st and that means that Dog Day finally arrived. In Mexico, at least 43 million households have a dog as a pet, according to data from the National Institute of Statistics and Geography (INEGI) In addition, it is estimated that 9 out of 10 people make a trip with their dog instead of doing it alone. So, to enjoy this day walking with your best friend in the car, we leave you here 5 tips for your can enjoy the trip as much as you with your company: Feeding your dog minutes before leaving is not recommended, as it is likely that you can suffer from dizziness along the way. The best thing would be to feed it about 4 hours before leaving, so that it has enough energy and avoid problems in the car. Read also: How to remove the smell of cigarette from the car On trips of a considerable distance, it is advisable to make some stops every couple of hours to help your dog destress from the movement and hustle of the car. Give him a break, take him for a few laps to stretch out and do his needs is important for the trip to be the most enjoyable for him. It is always best to consult with the trusted veterinarian the possibility of making a trip with the can. Performing a routine check-up, making health considerations depending on race and asking for recommendations from the doctor is indispensable to avoid unforeseen events, of which we might regret. Just as we like to indulge and stay in safe and fun places, we should look the same for our pets. Searching for pet friendly sites where you can enjoy your company without complications is ideal. They can be parks or hotels with green areas to run with them. Read also: What happens if you circulate without plates in the CDMX Dogs are guided and feel in confidence with odors that they already know. Packing blankets you're familiar with will help reassure the can, knowing it's a safe place with your company and their things. On the other hand, having water, prizes, strap and bags to lift your waste is indispensable. If you do not have a car, there is the possibility of renting one completely available for pets. Currently companies like Avasa, which has a collaboration with Laika, offer the first “ pet friendly ” fleet that will allow you to travel with your dog comfortably and without worries following the previous tips.\n",
      "---------\n",
      "Summary: \n",
      "Today is Dog Day, and in Mexico, 43 million households have a dog as a pet. To enjoy the day with your dog, here are 5 tips for a safe and enjoyable trip: feed your dog 4 hours before leaving, make stops every couple of hours, consult a veterinarian, find pet-friendly places, and pack familiar blankets, water, treats, and waste bags. Companies like Avasa offer pet-friendly rental cars for a comfortable and worry-free trip.</s>\n"
     ]
    }
   ],
   "source": [
    "print('Content: \\n{0}'.format(cont))\n",
    "print('---------')\n",
    "print('Summary: \\n{0}'.format(summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70b52199-ac36-4a07-9106-4cb29de8ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some summaries are rouchly finished due to the `max_new_tokens` constraint of the LLM, so for those cases, perform a gentle finish.\n",
    "summs_df['complete_summary'] = summs_df['summary'].apply(lambda x: finish_summary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a067595b-fbb6-46b5-9c0e-5c1ec4e614e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summs_df = summs_df[['content_en', 'complete_summary']].rename(\n",
    "    columns = {\n",
    "        'content_en':'article', \n",
    "        'complete_summary':'summary'\n",
    "    }\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7794bc5-0200-42ee-bb61-a6476b373971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some summaries might exceed 1024 tokens (BART-large hard limit) after tokenization. In those cases we perform a text shortening by extracting the\n",
    "# top_n most relevant sentences of a text. We save the shortened text in order to use that as the true label.\n",
    "# See the function `get_most_relevant_sentences` defined above for more details on how the text shortening is performed\n",
    "shortened_articles = []\n",
    "shortened_summaries = []\n",
    "for ix, row in summs_df.iterrows():\n",
    "    \n",
    "    print_progress_bar(iteration=ix, total = summs_df.shape[0], bar_length=50)\n",
    "    # article text\n",
    "    article = row['article']\n",
    "    # stable beluga summary\n",
    "    summary = row['summary']\n",
    "    \n",
    "    # Start with the article text:\n",
    "    \n",
    "    # initial \"top n\" percent of the text to keep, in order to shorten text in case of longer than expected text\n",
    "    perc_to_keep = 0.9\n",
    "    while True:\n",
    "        # tokenize the article text\n",
    "        inputs = tokenizer(article)\n",
    "        if len(inputs['input_ids'])>1024:\n",
    "            # article text exceeded 1024 tokens, so shorten the article text (keep only top n %)\n",
    "            article = get_most_relevant_sentences(\n",
    "                article, \n",
    "                embedding_model, \n",
    "                top_n_perc = perc_to_keep\n",
    "            )\n",
    "            # decrease the percetage to keep by 10% in case article text still exceed 1024 tokens\n",
    "            perc_to_keep -= 0.1\n",
    "            # keep iterating the loop\n",
    "        else:\n",
    "            # article text no longer exceeds 1024 tokens\n",
    "            break\n",
    "    # save the article text that didn't exceed 1024 tokens\n",
    "    shortened_articles.append(article)\n",
    "    \n",
    "    # Now for the summaries:\n",
    "    \n",
    "    # initial \"top n\" percent of the text to keep, in order to shorten text in case of longer than expected summaries\n",
    "    perc_to_keep = 0.9\n",
    "    while True:  \n",
    "        # tokenize the summary\n",
    "        targets = tokenizer(summary)\n",
    "        if len(targets['input_ids'])>1024:\n",
    "            # summary exceeded 1024 tokens, so shorten the summary (keep only top n %)\n",
    "            summary = get_most_relevant_sentences(\n",
    "                summary, \n",
    "                embedding_model, \n",
    "                top_n_perc = perc_to_keep\n",
    "            )\n",
    "            # decrease the percetage to keep by 10% in case summary still exceeds 1024 tokens\n",
    "            perc_to_keep -= 0.1\n",
    "            # keep iterating the loop\n",
    "        else:\n",
    "            # summary no longer exceeds 1024 tokens\n",
    "            break\n",
    "    # save the asummary that didn't exceed 1024 tokens\n",
    "    shortened_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f1c32-cd96-493e-8625-722a0651a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "summs_df['short_art'] = shortened_articles\n",
    "summs_df['short_summ'] = shortened_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7d91e-bab9-4b30-ba90-44592609faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summs_df = summs_df[['short_art', 'short_summ']].rename(\n",
    "    columns = {\n",
    "        'short_art':'article', \n",
    "        'short_summ':'summary'\n",
    "    }\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f70e7-da9d-40ba-b8c0-4f3479674288",
   "metadata": {},
   "outputs": [],
   "source": [
    "summs_df.to_json('BART_data_set.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
